# webinterface-imageai# webinterface-imageai

# ğŸ¨ GÃ©nÃ©rateur d'Images IA

Une application complÃ¨te pour gÃ©nÃ©rer des images avec vos modÃ¨les Flux et Hunyuan personnalisÃ©s, avec support des LoRAs et interface web intuitive.

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-green.svg)
![License](https://img.shields.io/badge/license-MIT-orange.svg)

## âœ¨ FonctionnalitÃ©s

- ğŸ”¥ **Support Flux et Hunyuan** : Compatible avec vos modÃ¨les safetensors
- ğŸ¯ **LoRAs dynamiques** : Ajout de LoRAs via URL pour personnaliser le style
- ğŸ–¥ï¸ **Interface web moderne** : Drag & drop, preview en temps rÃ©el
- ğŸ“ **Formats multiples** : 1:1, 4:3, 3:4, 16:9, 9:16 et plus
- ğŸš€ **DÃ©ploiement facile** : Local, Docker, ou Render
- ğŸ§¹ **Gestion automatique** : Nettoyage des fichiers temporaires
- âš¡ **OptimisÃ© GPU/CPU** : DÃ©tection automatique CUDA

## ğŸš€ Installation Rapide

### MÃ©thode 1: Installation locale

```bash
# Cloner le projet
git clone <votre-repo>
cd ai-image-generator

# Installation automatique
make install
# ou manuellement:
chmod +x setup_local.sh && ./setup_local.sh

# DÃ©marrer l'application
make run
# ou manuellement:
source venv/bin/activate && python app.py
```

### MÃ©thode 2: Docker

```bash
# Construction et lancement
make docker
# ou manuellement:
docker build -t ai-image-generator .
docker-compose up -d

# L'application sera disponible sur http://localhost:5000
```

### MÃ©thode 3: DÃ©ploiement sur Render

1. Forkez ce repository
2. Connectez votre compte Render Ã  GitHub
3. CrÃ©ez un nouveau service Web
4. SÃ©lectionnez ce repository
5. Render utilisera automatiquement `render.yaml`

## ğŸ“‹ PrÃ©requis

### SystÃ¨me minimum
- **Python** 3.10+
- **RAM** 8GB (16GB+ recommandÃ©)
- **Stockage** 20GB+ (pour les modÃ¨les)
- **GPU** Optionnel mais recommandÃ© (CUDA 11.8+)

### DÃ©pendances Python
- Flask 3.0+
- PyTorch 2.1+
- Diffusers 0.25+
- Safetensors 0.4+
- Pillow, requests, numpy

Voir `requirements.txt` pour la liste complÃ¨te.

## ğŸ¯ Utilisation

### 1. PrÃ©parer vos modÃ¨les

Placez vos fichiers `.safetensors` dans le dossier `models/` :

```
models/
â”œâ”€â”€ mon_modele_flux.safetensors
â”œâ”€â”€ mon_modele_hunyuan.safetensors
â””â”€â”€ loras/
    â”œâ”€â”€ style_anime.safetensors
    â””â”€â”€ style_realistic.safetensors
```

### 2. Interface Web

1. Ouvrez http://localhost:5000
2. **Upload** votre modÃ¨le safetensors
3. **SÃ©lectionnez** le type (Flux/Hunyuan)
4. **Ajoutez** des URLs de LoRAs (optionnel)
5. **Configurez** les paramÃ¨tres :
   - Dimensions (1:1, 4:3, 16:9, etc.)
   - Nombre d'images (1-4)
   - Steps, Guidance Scale
6. **Saisissez** votre prompt
7. **Cliquez** sur "GÃ©nÃ©rer"

### 3. API REST

```bash
# Status de l'application
curl http://localhost:5000/api/status

# GÃ©nÃ©ration d'image
curl -X POST http://localhost:5000/api/generate \
  -F "model_file=@mon_modele.safetensors" \
  -F "model_type=flux" \
  -F "prompt=a beautiful landscape" \
  -F "image_count=2" \
  -F "dimensions=768x512"

# Nettoyage des fichiers temporaires
curl -X POST http://localhost:5000/api/cleanup
```

## âš™ï¸ Configuration

### Variables d'environnement

```bash
# DÃ©veloppement
FLASK_DEBUG=true
FLASK_ENV=development
HOST=127.0.0.1
PORT=5000

# Production
FLASK_ENV=production
FLASK_DEBUG=false
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
TOKENIZERS_PARALLELISM=false
```

### Configuration GPU

```python
# Automatiquement dÃ©tectÃ©
device = "cuda" if torch.cuda.is_available() else "cpu"

# Gestion mÃ©moire GPU
torch.cuda.empty_cache()  # LibÃ©ration mÃ©moire
```

## ğŸ”§ API Endpoints

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/` | GET | Page d'accueil |
| `/api/status` | GET | Status de l'application |
| `/api/generate` | POST | GÃ©nÃ©ration d'images |
| `/api/image/<filename>` | GET | Servir les images gÃ©nÃ©rÃ©es |
| `/api/cleanup` | POST | Nettoyage fichiers temporaires |

### ParamÃ¨tres de gÃ©nÃ©ration

```javascript
{
  "model_file": "fichier .safetensors",
  "model_type": "flux|hunyuan", 
  "prompt": "description de l'image",
  "lora_urls": "URLs des LoRAs (optionnel)",
  "image_count": 1-4,
  "dimensions": "512x512|768x432|etc",
  "steps": 20-100,
  "guidance": 1.0-20.0,
  "output_dir": "dossier de destination"
}
```

## ğŸ³ Docker

### Dockerfile optimisÃ©

```dockerfile
FROM nvidia/cuda:11.8-devel-ubuntu22.04
# Support GPU + optimisations mÃ©moire
# Multi-stage build pour rÃ©duire la taille
```

### Docker Compose

```yaml
version: '3.8'
services:
  ai-generator:
    build: .
    ports: ["5000:5000"]
    volumes:
      - ./models:/app/models
      - ./generated_images:/app/generated_images
    deploy:
      resources:
        reservations:
          devices: [driver: nvidia, count: 1]
```

## â˜ï¸ DÃ©ploiement sur Render

### Configuration automatique

Le fichier `render.yaml` configure automatiquement :

- **Service Web** avec Gunicorn
- **Stockage persistant** pour les modÃ¨les (50GB)
- **Variables d'environnement** optimisÃ©es
- **Health checks** automatiques
- **Auto-scaling** selon la charge

### Limitations Render

- âš ï¸ **CPU uniquement** (pas de GPU sur plans standards)
- â±ï¸ **Timeout 30s** pour les requÃªtes HTTP
- ğŸ’¾ **MÃ©moire limitÃ©e** selon le plan choisi
- ğŸ“¦ **Build time** limitÃ© Ã  15 minutes

### Optimisations pour Render

```python
# ModÃ¨les optimisÃ©s CPU
pipeline = FluxPipeline.from_pretrained(
    model_path,
    torch_dtype=torch.float32,  # CPU
    device_map=None
)

# Steps rÃ©duits pour performance
default_steps = 20  # Au lieu de 50+
```

## ğŸ§ª Tests et Monitoring

### Tests automatiques

```bash
# Tests complets
make test

# Monitoring en continu
make monitor

# Tests spÃ©cifiques
./monitor.sh http://localhost:5000
```

### MÃ©triques surveillÃ©es

- âœ… Status de l'API
- ğŸ”¥ Utilisation GPU/CPU
- ğŸ’¾ MÃ©moire disponible
- ğŸ“Š Temps de gÃ©nÃ©ration
- ğŸ—‚ï¸ Fichiers temporaires

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨mes courants

#### "CUDA out of memory"
```bash
# RÃ©duire la taille d'image
dimensions = "512x512"  # Au lieu de 1024x1024

# RÃ©duire le nombre d'images
image_count = 1

# Vider le cache
torch.cuda.empty_cache()
```

#### "Module not found"
```bash
# RÃ©installer les dÃ©pendances
pip install -r requirements.txt

# VÃ©rifier l'environnement virtuel
source venv/bin/activate
```

#### "Safetensors invalid"
```bash
# VÃ©rifier le fichier
python -c "import safetensors.torch as st; st.load_file('model.safetensors')"

# TÃ©lÃ©charger Ã  nouveau
wget <url_modele> -O model.safetensors
```

### Logs de debug

```bash
# Activer le debug
export FLASK_DEBUG=true

# Logs dÃ©taillÃ©s
python app.py 2>&1 | tee app.log
```

## ğŸ“š Documentation AvancÃ©e

### Structure du projet

```
ai-image-generator/
â”œâ”€â”€ app.py                 # Application Flask principale
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ render.yaml           # Configuration Render
â”œâ”€â”€ Dockerfile            # Image Docker
â”œâ”€â”€ docker-compose.yml    # Orchestration Docker
â”œâ”€â”€ Makefile             # Automatisation des tÃ¢ches
â”œâ”€â”€ README.md            # Cette documentation
â”œâ”€â”€ web/
â”‚   â””â”€â”€ index.html       # Interface web
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_local.sh   # Installation locale
â”‚   â”œâ”€â”€ deploy_render.sh # DÃ©ploiement Render
â”‚   â””â”€â”€ monitor.sh       # Monitoring
â”œâ”€â”€ models/              # ModÃ¨les safetensors
â”œâ”€â”€ generated_images/    # Images gÃ©nÃ©rÃ©es
â””â”€â”€ temp/               # Fichiers temporaires
```

### Architecture technique

```mermaid
graph TD
    A[Interface Web] --> B[Flask API]
    B --> C[Pipeline Manager]
    C --> D[Flux Pipeline]
    C --> E[Hunyuan Pipeline]
    F[LoRA Downloader] --> C
    G[File Manager] --> B
    H[GPU Manager] --> C
```

### Personnalisation

#### Ajouter un nouveau type de modÃ¨le

```python
def load_custom_pipeline(self, model_path, lora_paths):
    """Support pour un nouveau type de modÃ¨le"""
    pipeline = CustomPipeline.from_pretrained(model_path)
    # Logique spÃ©cifique...
    return pipeline
```

#### Modifier l'interface

```javascript
// web/index.html
// Personnaliser les styles, ajouter des fonctionnalitÃ©s
```

## ğŸ¤ Contribution

1. **Fork** le projet
2. **CrÃ©ez** une branche feature (`git checkout -b feature/amazing-feature`)
3. **Committez** vos changements (`git commit -m 'Add amazing feature'`)
4. **Poussez** vers la branche (`git push origin feature/amazing-feature`)
5. **Ouvrez** une Pull Request

### Guidelines

- Code en anglais, commentaires en franÃ§ais acceptÃ©s
- Tests unitaires requis pour les nouvelles fonctionnalitÃ©s
- Documentation mise Ã  jour
- Style PEP 8 pour Python

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ†˜ Support

- ğŸ“– **Documentation** : Ce README
- ğŸ› **Issues** : GitHub Issues
- ğŸ’¬ **Discussions** : GitHub Discussions
- ğŸ“§ **Contact** : votre@email.com

---

**Fait avec â¤ï¸ et beaucoup de â˜•**

â­ N'oubliez pas de star le repo si ce projet vous aide !
